Speaker 1  0:30  
The interprofessional pain and headache rounds and clinical case series have been built on a 20 year history of delivering these programs at Tufts and Harvard, Massachusetts General Hospital, we've hosted a mix of participating clinicians and scientists from both institutions, with live lectures occurring at Tufts University, School of Dental Medicine and MGH lectures presented at the historic ether dome in the bullfridge building. Concurrent academic weekend conferences also have evolved from the rounds topics, many of which have resulted in multiple publications since we've provided virtual access at Tufts for more than five years, we were immediately prepared to shift as COVID changed most learning platforms. We now provide virtual access with the current platform to attendees from 21 countries. These presentations focus on the dissemination of evidence based content through internationally recognized speakers and case based presentations that include group discussion and interaction with the presenters. Way. I'd like to give a brief introduction for our esteemed speaker, Jonathan Jerry, I had the opportunity of reading some of his really great work, and some of our colleagues have read it in a number of across a number of settings. He's the science communicator with the McGill office for science and society dedicated to separating sense from nonsense on his scientific stage. He has a master's degree in molecular biology, and he brings his experience in cancer research, human genetics, rehab research and forensic biology to the work he does for the public. He was a creator, writer and a host of the YouTube show cracked science, which used the late night deep dive format to debunk pseudoscience and denounce bad science. With cardiologist Dr Christopher levos, he co host the award winning medical podcast the body of evidence, which aims to contextualize findings in the realm of health research and answer the public's most pressing questions about the biomedical sciences, while also being rather funny and entertaining, he talks about science every Friday on CTV Montreal news, and is regularly interviewed in both English and French languages. As we all know, the area of pain has been challenged, and this is an area where we need much greater focus on issues of science, as opposed to some of the challenges that occur in our field. So Jonathan, thank you again for doing this. Turn it over to you, and we'll welcome questions at the end.

Speaker 2  3:17  
Thank you very much for the introduction, and thank you again for the invitation. I'm very, very happy to be here this morning. I'll be sharing my There we go. Share my screen. I hope you can all something a little bit different, I guess, for your for your rounds, compared to the usual stuff. As was mentioned, I work at the McGill office for science and society at McGill University in Montreal, Canada. We're fairly unique in that our job is not to do PR for the university. We're not doing research, but we are answering the public's question about science, about what is good science, what is bad science, what is outright fake science. And of course, this pandemic has been has kept us very, very busy. So I want to talk about what, how to debunk this misinformation according to the best scientific evidence that we have right now. And I will begin by giving my little disclosure here. So I've ironically received a speaking fee from my own university to give a version of this talk to a different department through the the Faculty of Medicine and Health Sciences. So, to begin, is world on fire. And I'm asking this question because you, I'm sure you've seen this. This was from from the very beginning of the pandemic, burning cell towers out of baseless fear they spread the virus. There was this notion among certain members of the community that COVID 19 was not being caused by a virus, but rather was a consequence of 5g telecommunications technology that was being turned on all over the world, and that was that was having harmful effects on the human body. In fact, it got to the point where some of these towers were being burned down. This is from my quote, unquote, neighborhood here. Quebec. So this was not a 5g tower. Unfortunately. I mean, most of them were not even, did not even have 5g technology, but they just, they were telecommunications towers, and some activists decided to set them on fire to protect the rest of the world. You might have seen this tweet from the Food and Drug Administration in your country. So you are not a horse. You're not a cow. Seriously, y'all stop it. So they actually tweeted this out, out of their official account. This was, of course, because of ivermectin, which is an anti parasitic drug which has been adopted by some people as a as a perfect cure and prophylactic against covid 19, even though there's no good evidence behind that, and I will come back to ivermectin later on. During my talk in India, some people were being told to apply cow excrements on their head and on their body as a remedy against covid. 19, there was also a mention of cow urine. This got exported to the United States, where some anti vaxxers were telling their supporters that the new the new cure for covid was urine therapy. So please drink your urine and everything will be okay. In fact, if you go to Wikipedia, there's a whole page just on covid, 19 misinformation. And this is a table of contents, and this, with this screenshot, was actually taken a year ago, so I'm sure it's actually gotten worse since then. So this is how you might be feeling right now. What do I do with all of this? Is the world on fire. There's nothing. Nobody trusts science anymore. Everything is going downhill. So that was the first part of the talk. Actually, it's not as bad as it looks. And you may be wondering, okay, but I want to push back against this stuff, but I don't know how, and there are things that I worry about, so that's what I want to to address here. First of all, a few definitions, which I think will be very useful when we talk about misinformation. It is false information that is not known to be false by the sharer. So for example, if there's an article about the alleged toxicity of a vaccine that is false, it's not accurate, but the person sharing it believes it to be true, they are sharing misinformation, and this is often conflated in the media with disinformation. And disinformation is false information that is known to be false by the person sharing it, who may even have fabricated it. This is also known as a lie. You may remember when the phrase fake news was first coined, it was to describe these websites that were creating out of whole cloth, fake stories about Hillary Clinton, about Donald Trump in order to swing an election, in order to make some money from ad revenue from the traffic that they were getting, or just to have fun. So that is disinformation. And for your information, there's mal information as well, which I will not be talking about today, but this is true information, but that is shared deliberately to cause harm. Classic example is revenge porn. So a sex video is film. It is accurate, but it is then being shared in order to harm the people in it. So that is mal information. The last definition that I want to go over is pseudoscience, which is something that I tackle all the time in the work that I do. So pseudoscience is a collection of related beliefs about the world that are mistakenly regarded as being based on a scientific method, whereas having the status that science, that scientific truths now have it translates into fake science. So it looks like science, but it's not actually science. And unfortunately, there is no clear demarcation between science and pseudoscience. It is more of a spectrum. There are things that are very clearly scientific, there are things that are very clearly pseudo scientific. And there's a gray zone in between where some some interesting notions might be proto scientific. There might be a science in the works. It's not clear. So it's not always easy to figure out if something is a pseudoscience or isn't, because there is no clear line between them. 

One thing that is certain is that there is a lot of pseudoscience out there, and I've just placed a few, a few illustrations of that on the screen right now, there's a lot of stuff that somebody who doesn't know much about it may look scientific on its surface. They have scientific studies behind them. They are being sold with this patina of scientific legitimacy around them, but they are not actually scientific. And when it comes to addressing these in the public square and sort of pushing back against this misinformation and the pseudoscience you might be wondering about, for example, the backfire effect. And this came out in 2010 I believe the screenshot is from an earlier version of the manuscript. And this sent a chill down in science communication circles. This was a study done by Brendan Nyhan, Jason Reifler, and as they explained in their abstract, they were providing people with information that was false, and they were then issuing a correction in this experimental setting. And what they. Discovered is that there were some examples of what they called a backfire effect, so corrections actually increased misperceptions among the group in question. So you were trying to address misinformation, and it actually made things worse. The person doubled down and believed in it even more. And so for a while, we were all very depressed and scared because we thought, well, I guess we can't address these issues at all, because otherwise we're just going to make things worse. However, there have been many studies since on this alleged backfire effect that have shown that the original study would be detected was done in a highly specific context, and the backfire effect, if it even exists, is actually quite rare, so it's not something that we particularly need to worry about. Yes, there are people who will double down, but that is not the majority of people. Another issue that you might have in mind is, yes, but you know, if I, if I debunk this misinformation online, for example, if I write about this on Facebook and Twitter, I end up repeating it. And isn't it true that just repeating misinformation will make it appear, will just create this link in people's minds? Right? So if we're talking about the the false link between vaccines and autism, some people write a vaccines cause autism, and then you write, you know, an article saying that vaccines do not cause autism, and there's another headline saying there's no relationship between vaccines and autism, and there's all this noise about vaccines and autism. The idea is that people will remember hearing about vaccines and hearing about autism in close proximity to each other. So maybe there's a link within those two things. I'm not quite sure. I don't quite remember. So that is, it's a genuine concern, and that is why, for example, it's not a good idea to shine a spotlight on a tiny myth that no one has ever heard of, something that could be harmful, but that has gotten no traction whatsoever, because then you're just amplifying this correlation in people's minds that it's actually not true. It's also a good idea. Why? For example, giving a title to a piece that is, for example, is 5g causing COVID 19? Not a good idea. A lot of people just read the headline. They don't read the article. And if they keep seeing these questions being asked in the media about 5g possibly causing COVID 19, they might infer that, indeed, there is a link between 5g and COVID 19. So it is better to title our articles. For example, 5g does not cause COVID 19, and here's why. So this idea spreading concern, this is concern for spreading a link that is false but that will ring true in people's minds. It is important to keep that in mind. But the evidence so far is very far from definitive, and the evidence that we do have suggests that it doesn't often happen. So once again, genuine concern, but not something that we need to, you know, really panic about. There's an interesting model to try and minimize this possibility. There's no good evidence that this model works any better than any other way of going about this. But I just find it interesting, something that you may want to adopt if this is something that you feel strongly about. And this is the sandwich model, which is that, before you address a myth, you flag it as such, right? So it's the bread, you know, condiments and meat, and then the bread again, type of model. So the first, the first layer of bread is okay. What I'm about to tell you is not true, but it's been spreading around the internet, so we need to address this. Then you talk about what this myth is. There's this myth going around that causes COVID 19. Here's why it's not true. And then at the end, you repeat that this was done. This was not true. This was a myth. Do not believe this as a way of, sort of priming the brain to expect something that is not true. Again, not great evidence behind this, but an interesting model to to potentially try and try out, speaking of the literature on good practices when it comes to debunking misinformation, is still emerging. So what that means is that you will find contradictory results. You will find highly contrived situations where researchers bring in undergraduate students, of course, into their lab, and they try to recreate what social media is like using screenshots and what have you. And so it's not quite the same thing as the real world. There's this issue of playing catch up with the internet, which is that by the time a study gets funded and gets underway, they might be testing YouTube, but now all the kids are on Tiktok, right? So there is this, this delay effect because of that, all of that, all of those very important caveats being said. There are themes that do emerge from the literature that can guide us when we want to and have to address misinformation about health and pseudo scientific notions, and it is quite reassuring. So here we go. Very importantly, use facts. Facts often do work. You may think that nobody believes in facts anymore, in a post fact environment that is not. Quite true facts often do work to counteract misinformation, and they especially work if you can provide better explanations, because the brain and pores a vacuum. So for example, I can imagine a situation in which a patient brings up some kind of alternative medical intervention that they've been undertaking, and they said that it worked for them. And you might want to say, well, oh, that thing that you took, yeah, that doesn't work, that that's pure quackery. And then you end the conversation there, and you move on, and the patient thinks, well, but how else to explain that? I got better. So they were not feeling well. They did the thing, and then they felt better. And so they assumed that there's a causal relationship between those two things. And so you can imagine that in their head, they have a table, and you just kicked the leg off of the table, and now the table is unstable, because now they they got better, but they don't have an explanation for how they got better. And if you don't fill that void with a better leg, the brain will go back to its original explanation. So in this particular case, you may want to talk about the placebo response, which is often the answer to this question of, How did alternative medicine work? In this particular case, there are things like self limiting conditions, for example, the flu, if it doesn't kill you, doesn't last forever. Immune system kicks in, and so as you're feeling really bad from the flu, you reach out for whatever you can find, and then you get better. It's not because the thing that you took made you better, but just because it's a self limiting condition, your immune system kicked in. There's a there's the very important process of regression to the mean, which is a statistical artifact, which is that, for example, in the case of chronic pain, which I'm sure you're much more familiar with than I am, there are fluctuations in the severity of the pain, and sometimes there are flare ups. And so you go above the average value of pain intensity, and during one of those flare ups, you know, I can, I can imagine, you, you would want to reach out for anything that you can find out of despair, and then your pain goes back down to its average value, because it basically has to, I mean, unless it's a much worsening condition, you're going to go back to the mean value for statistical regression, reasons of regression, so it will appear as if this intervention work, whereas, in fact, it was just a statistical artifact. And then there's the issue of multiple treatments, which is that if somebody tells you that they got cured of their cancer because of homeopathy, they may not be telling you that they also have chemotherapy and surgery, right? So it's easy to sort of focus on one of the interventions and dismiss the other ones, when they're the ones that actually had had an actual impact. 



I'll be referring to a few case studies along the way to illustrate these, these examples, and the first one I want to mention is the one which was flagged to me when I was invited to give this talk, because I've written about Havana syndrome, and it's very interesting, this idea of needing an explanation for a phenomenon and reaching for anything that you can find. So I'm sure many of you are familiar with this, but in case, in case you're not so late, 2016 early. 2017 members of the American embassy in Havana, Cuba, they start to report these debilitating symptoms, strange occurrences. Many describe it as a sort of unidirectional, incapacitating sound, very intense. There's this pressure inside the ear. Some people experience vertigo, nausea. Then we get into sort of the mid range side effects that start to start to happen, difficulty concentrating, memory problems, sleep disturbances. Then we get members of the Canadian embassy in Cuba that are reporting similar occurrences. And then it starts to spread all over the world. And we get these reports from Australia, from China, from all over the world, just outside the White House. So what is causing this? In fact, you may remember your own vice president, Kamala Harris, her trip to Vietnam was delayed because they had heard that there was a possible Havana syndrome case there, and they didn't know what was causing it. And so as so as not to put her at risk, they delayed her flight. So again, the brain abhors a vacuum. It looks for an explanation, and when easy answers were unsatisfying, it turned to more eccentric explanations. So some people brought up the idea of a poison. Could it be that these diplomats were being poisoned through the food that they ate, the air that they breathe? But the problem is that many people in their entourage would also eat the same food and breathe the same air, and they didn't get sick. There was a hypothesis of neurotoxins and the pesticides used to combat Zika all over Cuba, but there were no native Cubans that reported being sick in that way. So it's kind of bizarre that only the American diplomats were targeted in this way, and then they turn into these experimental weapons. Could it be an infrasound weapon? So a sound that is so low in pitch you can't actually hear it, but it would have an effect on the body. The most infamous type of Infrasound is the brown note. This idea that at a certain pitch, when when the body feels it, it provokes involuntary defecation. But the brown note is a myth. It was. It was actually tested on Mythbusters. It doesn't have. In Ultra could it be an ultrasound weapon, a very high pitched sound, but these waves need very close contact to propagate, and they're easily blocked by walls. And so if you're trying to attack an embassy from the outside, you know you have, you have a truck there parked, and you've got your your ultrasound weapon, those ultrasounds are not going to penetrate those walls, and it would also have massive energy needs. So where do you hide the generator that is needed to make this work? Then it was this idea of a microwave weapon. As far as I can tell, these experimental weapons so far, they could be quite unreliable. They're also in need of these imposing generators, and they would also mess with the electronics in the diplomats house, which and they were not affected. But then they brought in the fray effect, which was reported. It's an interesting effect whereby you can hear microwaves. Or you wouldn't think that you could hear microwaves, but in certain circumstances, you can. And so they thought, well, there you go. It was a microwave weapon. They reported hearing a sound. It must be through the fray effect, but the Frey fact requires near silence to perceive it, and the sound was very, very loud. It turns out that somebody managed to record the sounds. It wasn't just happening in somebody's ears. There was an actual sound, and it was identified as being made by crickets, a very specific species of crickets. And they're actually they're very, very loud. So that seems to be what the sound, the mysterious sound, was. And the best explanation that I could find for what happened is mass psychogenic illness. And if you want to dig deeper into this, it's a very good book about this by Robert Baylor, Robert Bartholomew. It's called Havana syndrome, mass psychogenic illness. And the real story behind the embassy mystery and hysteria. And there are many historical examples of these kinds of mass psychogenic illnesses, where these non specific symptoms, they get interpreted in light of some, you know, massive amount of stress that is being felt by, for example, diplomats in a country that doesn't really like them, and that can then spread to other people, who then also start to experience insomnia and vertigo and these episodes of stress, and it turns into something, even though there was nothing really there. Again, we don't really know what is going on with Havana syndrome. I'm not an expert on Havana syndrome, but that seems to be the most plausible explanation that we have at the moment. So going back to how to debunk misinformation, I mentioned that facts are very useful. We shouldn't forget about facts. But sometimes facts are not enough, because sometimes somebody's some belief becomes part of somebody's identity. And so when you attack a particular belief, when you attack a bit of misinformation, when you attack a specific type of pseudoscience, these people feel attacked themselves, and it can be very hard to have productive conversations with people like that who strongly identify with being an anti Vaxxer. For example, there are a few tips that have emerged. One of them is to start with values. Too often these conversations are very antagonistic, and you're being perceived as the enemy, but if you make the other person realize that you actually share the same values when it comes to these things and when it comes to vaccines. For example, I I'm very pro vaccine, but I want vaccines that are safe. I want vaccines that are effective. I want vaccines that are affordable. And same thing with the food supply. I want food that is that is affordable. I want food that is nutritious, that is tasty, and so when you begin by voicing what your values are on this and the align with the values of the person that you're speaking to, all of a sudden you're not speaking across from each other, but you're speaking next to each other. You are on the same side of the aisle, and you're both looking at the evidence, and that can help kind of diffuse the antagonism that can otherwise occur. Another bit of, a little bit of a tip there is to be empathetic, which, which can be hard. And of course, throughout the pandemic, everybody's patience has has gotten very, very down to the wire. But being empathetic can really help and understanding that somebody is very anxious and very stressed about something they believe in that, you know, is inaccurate. I mean, it doesn't change the fact that they are stressed about this, and they have real anxiety over this. And to be empathetic and to voice that empathy can also be conducive to a good a good conversation. It's also important to remember that you may not be able to change somebody's mind on the spot, but you can act as a pebble in their shoe, which means that this conversation that they've had with you might stick with them, and just like a pebble in your shoe, they're going to walk around and it's going to annoy them. It's going to keep they won't be able to flush it out of their out of their brain, and they will keep going back to it. And maybe a few months down the road, they'll be ready for a second conversation, or maybe they'll be ready to have a conversation with somebody else about this topic. So we shouldn't dismiss the importance of having conversations that do not resolve in somebody suddenly changing their mind about an important belief. Sometimes these things take time, but your conversation, if it is empathetic and if it's a good. Conversation can actually act as a pebble in their shoe.

Speaker 2  25:04  
But speaking of what happens when identity takes over, I mentioned ivermectin earlier, and I've written about ivermectin as well. So as I'm sure you know, it's a very useful drug for the treatment of certain infections in humans and animals. Then came COVID 19, and of course, everybody was trying to find any kind of treatment for COVID 19, there are many, many, many molecules that have antiviral activity in the lab, meaning that when you put them in a culture flask, you know, with cells and culture that are infected with a virus, that molecule will prevent the virus from making copies of itself. That's what an antiviral is. But just because something has antiviral properties in vitro doesn't mean that it will actually translate into a proper antiviral that is useful in humans. So there was this in vitro study done in African Green Monkey kidney cells with SARS cov two using high doses of ivermectin, much higher than what is typically given to humans. And it showed promising results in that it was, it was, it had antiviral activity against SARS, COVID, two. Then there were a few studies done in humans. There was a meta analysis of these studies showing a positive effect. But unfortunately, that meta analysis was skewed by one big study, and it looks like that study never happened. And if you're interested in hearing more about this on the podcast, and I co host the body of evidence, I actually interviewed Gideon Meyer, which Katz and Jack Lawrence, who's Jack Lawrence is a student in England who actually first came across evidence of scientific fraud in the ivermectin COVID 19 literature. And that kind of snowballed into an investigation. And there have been many fraudulent studies about using ivermectin, studies that could not have happened as described, studies where you can clearly see entire sections of the data set that's been copied and pasted from one patient to the next. And unfortunately, there's no good evidence right now that ivermectin has a fantastic ability to either cure or to prevent COVID 19. But as you're aware of, ivermectin became politicized, and it started to inform people's sense of identity, and with those people, facts were not enough. You couldn't just say, well, there's no good evidence ivermectin works. These papers look like they're fraudulent. It wasn't working. There was it was being deflected, and they felt personally attacked. And some of those people were anti Big Pharma, and ivermectin is all patent, so pharmaceutical companies can't profit too much from it, and that's something that these people like. And so their reasoning is, well, it must work because they can't profit from it. Some people were very conspiracy minded, which is that, okay, so it works, but pharma doesn't want you to know that it works, because they can't profit too much, so they're hiding the truth from you. So that played into this conspiracy narrative that ivermectin is a great treatment, but they're hiding it from you because they want to profit off of newer drugs that are still unpacked. Then there were the COVID minimizers who didn't like the public health measures and saw no need for them. And ivermectin became a great justification for that. See, you just take this drug that is well known, well tolerated, you take it prophylactically, and you'll be fine. And then you have the non conformists, which is people who don't believe in the scientific consensus on any issue, they think that the consensus is bought for by pharma money, or it's made of idiots, and they like to listen to the truth telling Mavericks, the robes, the fringe views, and those fringe scientists were endorsing ivermectin, therefore they must be onto something, and the scientific consensus is wrong. So this whole ivermectin narrative basically resonated with the identity of a lot of people who had those kinds of values, and in those cases, facts are just not enough. Coming back to how to debunk pseudoscience you want to use trustworthy and independent sources. So some people have a pathological distrust of governments and corporations. I have what I believe to be a healthy distrust of governments and corporations, but for some people, it is pathological. They distrust any consensus that emerges from them. They think that governments are completely paid for by corporations, and corporations are only interested in making money. And so they will keep telling you, follow the money. Follow my see is follow the money. And you'll see that this whole line of reasoning is corrupted. Of course, they never follow the money when it comes to the people that they idolize. But they only they all. They always do it for the people that they disagree with. All that to say that, if possible, it is better to share information. Of course, some sources that do not have a clear agenda. If Pfizer has written a brief saying that, you know, we at Pfizer say that our vaccine is 93% effective against COVID, trust us. They may be right. They may not be lying. But of course, if you're using that as you know, as evidence, a lot of people will look at this very suspicious. Well, of course, Pfizer would say that they want to sell their vaccines. There are sources that do not have this, you know, clear money making agenda, for example, I am tangentially associated with the science up first initiative in Canada, which is a group of independent scientists and physicians and healthcare professionals who get together and who, and we have these campaigns on social media to tell the public specifically about COVID. 19 right now. What do we know about COVID? What do we know about the vaccines? What are some of the misinformation that you might have heard and we're not funded by by pharma, so those kinds of sources of information do not have this clear agenda are better if you're trying to convince somebody, obviously, and also, very interestingly enough, despite what your Facebook feed and watching CNN really do to believe most people do still trust public health agencies and independent scientists, especially in times of crisis. That may be changing a little bit in the United States right now, I'm not sure, but based on the data that we have so far, sometimes the fringe voices are very loud, and it makes it appear as though they are much more popular than they are. But actually, good public health agency information can still change minds. Another thing, which is, you know, something that I've had to learn and and also kind of unlearn is, is don't write academically. So if you are addressing these issues for the public, you want to avoid technical terms unless they are necessary, and you want to explain the technical terms that are necessary. We go to university. We are taught how to write in this very dry, academic, objective, detached kind of way we're using big technical words. But when it comes to talking to the public about these issues, we have to unlearn all of that and right in a way that is much more accessible. It's important to keep in mind that most people have no idea what neurons look like. Most people don't know where DNA is in our body. They've heard of DNA. They know it's it's part of us as our blueprint, but they don't really know where it is. So it's easy for us to fall for the curse of knowledge, which is that you don't realize that what you know is not known by the people you're speaking to. You just assume that, of course, everybody knows about this stuff. You don't even question it. But actually, you kind of have to take a step back and go, Wait a second. Do they do they know this thing that I take for granted? Maybe not, which is why it is important to use analogies and metaphors and other figures of speech as needed. A very helpful tip is to ask yourself, would my grandma understand this unless, of course, she was or is a doctor or a biochemist or something to that regard, but then pick a different relative. But this idea of having a reader in mind, right? Somebody who does not have your university studies, would they be able to understand this? I think the most important tip in science communication circles is always to use storytelling, and this is something we don't do enough of, because misinformation itself often spreads virally because it is tied to a personal story. I had the misfortune of watching this thing called Vax to the people's truth. It pretends to be a documentary about vaccine related adverse events, specifically the vaccine autism, false connection. It's a piece of propaganda and but it's a very convincing piece of propaganda, because this is what it looks like. It is essentially a series of interviews, often with moms with their child, and they almost all follow the same structure, so they talk about how their child was wonderful at first, and there's soft acoustic guitar music in the background, and you see pictures of the baby smiling, and then they got the MMR shot, and they were never the same. And then the mom starts crying. And there's an accumulation of these anecdotes, these testimonials, for an hour and a half. And I can very easily imagine that if I'm a new parent, or if I'm a parent to be and I see this, I'm going to start getting very nervous, because now there's an accumulation of anecdotes, and I'm a little bit scared now, am I? Am I being lied to? Is there something wrong with this thing? And of course, then you enter the anti vaccination infrastructure, which is very, very well funded, and which might scare you away from giving your child very safe and effective childhood immunizations. So the reason that this works is that our brain is wired to respond to stories. We are storytelling species, and we can also use that on our side, because a narrative can be used to convey science in a compelling and memorable way, or also as a hook to guide the audience into the scientific data. 

Speaker 2  34:42  
For example, I just previously said, random you, if you, if you ever, if you've ever read a piece in the newspaper about a health, some kind of health story, it almost always starts with an anecdote. And this is a piece I found in The Globe and Mail. And it goes like this, like a lot of people when Toronto Life Coach and Speaker Ryan. Carry is about to give a speech in front of a crowd. She reminds yourself to breathe, and there's a quote, and then we and then we go into breath work. Is there evidence behind breath work or not? So journalists are taught to do do, to do this all the time, because it works. It helps. It helps the reader focus on a person that they can relate to, and you follow their journey, as opposed to just starting with facts and starting with with numbers, which which are a little bit on the dry side. Um, another tip is to point out fallacies and biases responsibly. So pseudoscience often appears believable because of biases in our thinking. So ways in which our thinking is skewed away from the truth away from being reliable in ways that are very predictable. And then there are errors in logic that are known as fallacies, that appear to be logical, but they're not, but they're very convincing. And I'll give you just a handful of examples. When it comes to health related pseudoscience, the most popular ones are the appeal to nature, right? So it's natural, therefore it must be good for us, it must be safe for us. There's a reason why we're spending so much money removing asbestos from our buildings. Asbestos is not safe for us, but there is this very deep wiring in the brain that tells us that if something is natural, it must be beneficial to us and it must be safe in its consumption. And if it is synthetic or artificial, then it's not good for us and it is not safe for us. That is a bias. It's a cognitive bias. It is not true, and it can be weaponized as a logical fallacy. And you see this all over the wellness space. So it can be and can be useful to point this out. Like to give examples of things that are natural, that are not good for us, and things are synthetic, which are perfectly safe for us. You know, the dose makes the poison. We have to test these things to know how safe they are, and other biases. The appeal to antiquity, which is, oh, well, this day, it's been used for 200 years because it works. Otherwise, why would we still be using it? Of course, I don't need to tell you that for centuries, bloodletting and leeches were used in medicine because there was nothing else, and apart from a few very specific applications, now, medicine has moved on. So just because something has been used for a very long time does not actually imply that it is working. And the biggest bias, I think, the most important bias in our brain, is the confirmation bias. And this something that we are all we can all fall for. We have to be aware of this, and it is starting from a conclusion that we like and working backwards. So you start by saying, I believe that this thing works. So now I will go on either on the internet, I will find papers that support my view, and I will dismiss those that disagree with me, and then I will convince myself that I've done my own research, and I've been very objective about this, but you know, it just so happens that my conclusion was proven true. And again, we're all susceptible to this, and this is something that we have to struggle to to, to exert ourselves from emphasize the consensus, if there is one, obviously, when COVID 19 started, there was no consensus, because we didn't know anything about this. New viruses don't come with instructions manuals, but eventually there's enough evidence from different lines of inquiry that converge in the same direction, and you get a consensus. And very often, what happens in pseudoscience is that the mainstream view and the fringe view are put on equal footing. They're given this false balance. And if the public doesn't know that one of them is a consensus and one of them is a fringe view, they will think that there's a genuine uncertainty, there's a genuine debate happening in the scientific community. So sometimes can be very helpful to remind people that, no, no, the weight of the evidence is here. We know this for pretty much for a fact, and that person over there has a very, very fringe view. They're just very, very loud. And that can put things back into perspective on social media. It can be very useful to remind people to slow down. There is evidence that people often share misinformation, not because they want to cause harm. I mean, it's misinformation. They don't know that it's false, simply because their attention is focused on factors other than accuracy, they don't stop to ask themselves, is this true? And so by reminding them to pay attention, to slow down and to ask themselves, if this information is active before sharing, we can reduce the spread of misinformation. You know, it's the social media companies have all these incentives built into their system to get us to react very quickly in anger and disgust and to share. But you have to ask yourself, you know, will somebody die if I don't share this right now, if I take the time, I don't have time now I'm at work. I don't have time to read the article. I will read it tonight, and then I'll figure out if this thing looks legit or not. So nobody's going to die if you don't share that particular tweet. So if we all slow down, we could contribute to slowing down the spread of misinformation and Fauci. Finally, avoid shaming, be empathetic. You know, it's important to remind all of us that ordinary people who fall for misinformation do not deserve scorn. There are people that are generating disinformation and that are profiting mightily from it, and I do believe that these people deserve scorn, but the people who just fall for this, they do not deserve scorn, because when was the last time that you change your mind after being called an idiot? Right? It doesn't. It doesn't really work. I think there's value in and this is especially in one on one conversations in the real world. But there's a lot of a lot to gain from listening to these people first, even when you know what they're about to say, you know that this is misinformation. Listening first is good. It establishes a relationship of trust. It means that you care, and acknowledging the validity of their worries is important as well. I understand that you were stressed out about this. I would be too. You may want to concede the parts that they got right. You know, I understand that you are worried about the pharmaceutical industry and the and the and the influence that it can have on on healthcare professionals. I worry about this as well, and then present active evidence. But despite that, you know here's why, why we know that the covid 19 vaccines are safe and effective. Here are the studies that have been done, but starting by listening, by acknowledging the validity of their worries, conceding the parts of the gut right, and then presenting the evidence. And then you can use your personal experience as an example, if it exists, if it is about discussing childhood vaccinations with with a parent who is hesitant. And you have kids and you have vaccinated them, talking about bad examples, and, you know, I have three kids, and they're fully vaccinated, and nothing wrong you know happened with them. These vaccines have been very, very well tested using that again, that storytelling, personal experience, it can really make a difference that being said, you may be very, very compassionate and still draw the ire of people who feel offended nonetheless. And that brings us to our last case study for today, which is multiple chemical sensitivity. So for those of you who don't know multiple chemical sensitivity, which goes under by different names as well, it is a diagnosis or a syndrome of non specific symptoms that can affect seemingly every organ system in the body. The culprit that is being blamed within this diagnosis is small concentrations of chemicals that the rest of us tolerate. It can be perfumes, can be air fresheners, paint, scented products, etc. And so the question becomes, how are these chemicals causing harm? Are they causing harm? What I found very interesting recently is that the government here in Quebec noticed that there were many more diagnoses of multiple chemical sensitivity than were expected given the size of our population. And so in order, in order to address this the needs of this population, our government tasked our public health agency in Quebec, the inspq, to look deeply into the literature to see what was known about NCS. And so the inspq spent almost a decade looking at this whole literature and then writing a very long report about this. And then I wrote about this for for McGill. And just to give you an idea of how massive this endeavor was, this is an 840 page report started in 2012 an exploratory look into literature, then in depth searches in 2013 of 28 different research databases, plus additional search engines and platforms. Then an additional search in 2019 to see what had been published since. So they analyzed a total of 4028 documents, most of which were peer reviewed scientific papers.

Speaker 2  43:41  
And they looked at the data behind several hypotheses that were brought up to try and explain multiple chemical sensitivity. Is it genetics? Is it neurobiology? Is it the immune system? Is that oxidative homeostasis is disrupted? Is there neuroinflammation? Is there a change in the olfactory system, or is it psychogenic, and what they boil it down to is that the best answer that we have right now is chronic anxiety being a causal factor for MCs. And as they write, you know, the authors of this report rebut the hypothesis that there is a relationship between MCS and the toxicity of chemicals present at normal concentrations. Nonetheless, what is being experienced is the symptoms themselves are very real, and there are real repercussions to that. It is a real health issue, and they say that there should be Centers of Expertise specializing in MCs that should be set up, but that, as far as we can tell right now, this is not being caused by the toxicity of these chemicals at normal concentrations. I wrote about this for our office at McGill. I felt like my piece had a lot of compassion in it. I specifically said nobody's calling these people crazy. That's not what is going on. Despite that, this was picked up by people in the community who have MCs, and I got an avalanche of emails people who were dearly offended by what I had written. I got the accusation that I had based this entire article on a single study, because they didn't understand the difference between a report of 4000 studies and a study. I was accused of showing no compassion for very real symptoms, even though there were multiple sentences there where I showed genuine compassion for these people, I was accused of committing an ethical violation, and that this article should be retracted and I needed to publicly apologize. Somebody told me that they were told that a course of antibiotics had disabled the two toxin removing chromosomes that they had, which is why they had MCs, what they had been told I studied human genetics. I know that this is not true. We don't have chromosomes that are just dedicated to removing toxins from the body, but this is what they had been told, probably by a naturopath. And so it was, it was very, very frustrating to have written, you know, to have this report that comes from a good place of the government wanting to act and do something. This is the answer that the literature gives us. I report on them with a lot of compassion, and despite that, because it's not the conclusion that they were looking for, these people were very angry. So that can still happen. So finally, for your sanity, I want to bring you my most important slide. If you are interested in tackling misinformation and pseudoscience. And this is the slide, the people who are strongly against you, they can hardly be reached. And I don't write for these people, right? I don't think that it's a good investment of time and energy and mental stress to try and reach the people who are very, very very strongly against me. The people who are strongly on my side, they can amplify my voice. They can share what I do my work, with people that I couldn't reach otherwise. But I write for the people in the middle, the people who are undecided, the people who are on the fence, who are confused. They've heard one thing, they've heard the other thing. They don't know what's true, and that is my target audience, so I would strongly invite you to not be this person who is not coming to bed because someone is wrong on the internet, you can't change. You know, you can get rid of irrationality and scientific illiteracy on the entire planet, but you can certainly make a difference with people who are genuinely and understandably confused. So here are some links for you if you want to take a screenshot of this slide before I stop sharing my screen and we go to the Q and A. I put up first here some good resources on debunking and science communication. I mentioned the science of first initiative. There are some podcasts that I recommend, some YouTube channels. Also, you don't have to reinvent the wheel. You can share content that already exists. All the case studies that I mentioned are things that I've written about from McGill. So you can search for these on our website at McGill, dot C, slash, OSS, and if you want to find me in my work, if you want to reach out at me on Twitter or via email, all of that is written there. So again, thank you very much for your attention. I hope that this was useful and educational, and I will be answering questions now.

Speaker 1  48:10  
This is really extraordinary. Thank you very, very much, Jonathan, we have a couple questions in the question section, and I have actually a quick one sure for you, actually two. One is you use the word flare when you talked about chronic pain. And most recently, I've had my students never use the and my patients never use the word flare, because it implies that there's some underlying pathology going on with the patient. So I just wanted to challenge you for the use of that word, sure,

Unknown Speaker  48:40  
absolutely you're the expert. It implies

Speaker 1  48:43  
some causation. But going on from that, what we see a lot of professional conferences where there's some nice work being done, usually termed a bench to bedside, okay? And as you're aware of this, and a lot of times in professional conferences, some of the junk signs is embedded into the conference itself, so you see a legitimate things going on, then people sort of off the rails. And we recently had a facial pain conference where we found that special nutrition efforts can fix all pain conditions whatsoever. What are your What are your thoughts about that and how some of our own scientific colleagues sort of give a pass and embed some of this in their educational efforts.

Speaker 2  49:32  
Yeah, I mean, I could talk about this for an hour, and in fact, I have. It's on a podcast. It's going to come out next week. It's called Embrace the void I was I was interviewed on this topic of, how do the How does a non scientist, how can they evaluate a paper as to whether it's a good paper or not it ties into what you're mentioning, which is that there's a lot of bad signs out there, and it's cut and the call is coming from inside the house. And what do we do about this? How do we recognize it? It's a very complicated issue, because, as I. Sure. You know, science is a human enterprise. There are bad incentives in the scientific research system that we have come up with. One of these is that we need to publish a lot. We need to publish in journals with high impact factors. And so it leads otherwise very honest researchers into sort of cutting corners and P hacking and doing things that, and then coming to conclusions that aren't that aren't true. And then there, of course, there are researchers who have this ideology behind them and who will pursue it, and they will do a study that is subpar, for example, but it will come to the conclusion that they wanted to get and then that gets presented at a conference. What do we do about this? I mean, it's, it's it's about, you know, unfortunately, it's about teaching people how to be scientifically literate and how to look not for a single study, but for the body of evidence on a particular issue. Because individual studies can be wrong and they can be biased, but when you look at all of the studies, hopefully they will sort of point in a common direction, and it's about teaching people to be to be better aware of these things. I wrote about P hacking recently, which was a challenge to sort of explain what P hacking is to to to a non scientific readership without bringing in equations and too many statistical concepts into it. But one of the solutions to P hacking is to teach science students, right when they're undergrads or when they're master students, what P hacking is and how not to do it like this. Don't do this. Don't, you know, start recruiting some participants or some samples into your study. Then run your test, and then we don't, you don't get a highly significant P value. You keep recruiting, and then you do the stop and go motion until you get a significant P value. That is P hacking, right? If you are, if you're testing multiple things in your data set, that is fine for exploratory purposes, but don't go and say, Oh, we set out to look for this thing, and we found it, and therefore we've confirmed this link, because that's not true. You've tested so many hypotheses, you were bound to find a false positive, so that can inform your hypothesis for the next study, and then you can look specifically at this thing. So I think it starts with educating our students properly as to what is good scientific conduct and what is not.

Speaker 1  52:19  
There's a few more questions in here, a number of questions. Michael Chapman has a couple. Roxanne Barry. Roxanne Barry Bavarian, Michael talks about the issue of, well, I'll let you take a look at can you see the questions?

Speaker 2  52:35  
It's under Q and A, yeah. Oh, boy, okay.

Unknown Speaker  52:42  
Yes. Let's see

Unknown Speaker  52:45  
the question is

Speaker 2  52:54  
to question the methodology, something integrative, systematic reviews, really. I mean, the only, the only thing that I can say about systematic reviews and meta analysis is that, yes, sometimes they can be wrong, and that is very infuriating, because it's garbage in, garbage out. I'll give a quick example cranial sacral therapy, which is an alternative medical intervention where people believe that they can feel the pulse of the cerebrospinal fluid. They believe that it has a pulse. This pulse is distinct from from, from your pulse, your heart pulse, and that they can diagnose you based on that CSF pulse, and then they can move the plates of your skull around to treat you. And there was a meta analysis of this which seem to show that it works. But when you look at the 10 studies that are inside of this meta analysis, they're all garbage studies, and they all have massive flaws. And so unfortunately, I used to say, just look for a good meta analysis or good systematic review on a topic, and you will know what the truth is in that particular discipline. But now these things are being weaponized by people who believe in alternative medicine, and when you put a bunch of bad studies inside of a meta analysis, the result that you get is is technically unusable, but you can sell it as being the truth. So some skepticism of systematic reviews and meta analysis is justified because it's always a question of what you put inside of them.

Speaker 1  54:21  
So going along those lines, and we sometimes hand patients Cochrane Reviews because there's a plain language summary in them, they're usually a little bit higher, higher quality, and tend to offend everybody. But we give them the patients Roxanne, Dr Bavarian has a question that sort of relates to that you're open to ask a question, if you like Dr Bavarian. Oh,

Speaker 3  54:47  
I apologize my question is so broad, and you kind of answered throughout your entire lecture, but, and I mentioned multiple chemical sense to be my question, but maybe I should be more specific that so we were. Treating neuropathic or facial pain, and oftentimes patients have like, comorbid diagnoses of like chronic Lyme or fibromyalgia, small fiber neuropathy, dysautonomia, these kind of conditions that are from what I'm a resident here, and from what I gather like, it's still debatable, like, to what extent these can cause these kind of symptoms, that condition is real, or it can cause these kind of SO and these patients are often, like, very hostile, too. I'm not often, but like, maybe a couple times a year there'll be someone who's who comes in angry. And I guess I just wanted to hear what you're i You're not a clinician, right? You do, but still, you gave very good advice.

Speaker 2  55:44  
Despite this mad, this major flaw my background,

Speaker 3  55:50  
I loved your talk and and just what your advice is on, on conditions where there's still there's still controversial, and there is a high relationship with anxiety, but you want to be really sensitive to them. And going into the craniosacral therapy too, we see especially working in head and neck. We see it so much. But I don't know if this is unethical, but I'm kind of like, well, you know, that's the least invasive procedure, apart from it taking time and money. It's not an anti convulsant medication that I would give them. So I kind of say, well, yeah, we don't really understand it, but if it's helping keep doing helping, keep doing it. So two questions, yeah,

Speaker 2  56:25  
I've heard from a lot of MDS who likewise feel so you know, at a loss for solutions, that they're like, Okay, well, you want to do this alternative therapy. I don't see major risk to it. Go for it. If you feel like it helps you go for it. I would add as a little asterisk, well, yeah, I'm not a physician, so I don't, I don't experience this kind of, you know, what else can I do for my patient? But some of these alternative medicines, they are worlds onto themselves, and once you're inside of them, you can go down the rabbit hole and become an anti Vaxxer. For example, I'm not saying this happens in happens in in every case, but it's just something to keep in mind as to your first question. I think what's really at the center of it is uncertainty, which is that, as a scientist and as physicians, you know, I and you were sort of trained or and we might even be predisposed to being okay with a certain level of uncertainty, with not knowing, but the average person is not. There's a reason why astrology is very popular right now. We are in very uncertain times, and astrology, even though it doesn't work scientifically, it gives you the illusion of control over your life. And so when you go see a naturopath or what have you, and they give you a diagnosis like chronic Lyme disease, even if the diagnosis is not real, it's not a real medical entity. It feel it plugs a hole in the brain, right the brain, and pours a vacuum, oh, boom, this is what I have. And now I can join other communities online of people who have this diagnosis, and we can talk to each other. And again, the social aspect, we're social animals, right? So now it can congregate with people who are just like me, but when they come and see you and you say, Well, I don't believe this diagnosis is real. I get that your symptoms are real. I don't have a diagnosis for you. I'm not sure what to do with this particular case, you are doing the best that you can, and you're okay with the uncertainty, but that person may not be, and that is a very large issue that you will not be able to solve in the time that you have with your patient. I suspect of how to become okay with not knowing like I also have a condition that has never been properly diagnosed, and I'm okay with it because I understand scientifically how difficult it is to pin down what's going on. But for most people, it's not. So just keep in mind that it's that's what's happening down. Down there is, is that this, they want to be certain of this thing, and you don't have that certainty to offer them, but there are people out there who do have that certainly, even Though it's it's wrong. Ah,

Transcribed by https://otter.ai
